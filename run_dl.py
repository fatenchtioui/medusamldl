# import streamlit as st
# import numpy as np
# import pandas as pd
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.metrics.pairwise import cosine_similarity
# import torch
# import torch.nn as nn
# import torch.nn.functional as F
# import pickle
# import io

# from matching_dl import MatchingDLTrainer

# def run_deep_learning(profils_df):
#     st.title("ü§ñ Matching Intelligent avec Deep Learning")

#     if profils_df.empty:
#         st.error("Aucun profil charg√©")
#         st.stop()

#     profils_df['competence_clean'] = profils_df['competences'].str.lower().str.replace('[^\w\s]', '', regex=True)
#     all_skills = profils_df['competence_clean'].tolist()

#     vectorizer = TfidfVectorizer(max_features=500)
#     X_train = vectorizer.fit_transform(all_skills).toarray()

#     # Section Entra√Ænement
#     if st.button("üîÑ Entra√Æner le mod√®le DL"):
#         y_train = np.array([
#             1 if any(k in skills.lower() for k in profils_df['key_word_ia']) else 0
#             for skills in profils_df['competences']
#         ])

#         trainer = MatchingDLTrainer(input_dim=X_train.shape[1])
#         metrics = trainer.train(X_train, y_train, epochs=20)
#         st.session_state.dl_model = trainer
#         st.session_state.dl_vectorizer = vectorizer
#         st.success("‚úÖ Mod√®le entra√Æn√© avec succ√®s !")
#         st.json(metrics)

#     # Section Export/Import du mod√®le
#     # Section Export/Import du mod√®le
#     st.subheader("üì¶ Gestion du mod√®le")
#     col1, col2 = st.columns(2)

#     with col1:
#         if 'dl_model' in st.session_state and 'dl_vectorizer' in st.session_state:
#             model_bytes = st.session_state.dl_model.export_model(st.session_state.dl_vectorizer)
#             st.download_button(
#                 label="üíæ Exporter le mod√®le",
#                 data=model_bytes,
#                 file_name="matching_model_and_vectorizer.pkl",
#                 mime="application/octet-stream"
#             )
#         else:
#             st.warning("Entra√Ænez un mod√®le avant l'export")

#     with col2:
#         uploaded_file = st.file_uploader("üì§ Importer un mod√®le", type=["pkl"])
#         if uploaded_file is not None:
#             try:
#                 bytes_data = uploaded_file.read()
#                 trainer = MatchingDLTrainer(input_dim=500)  # Doit correspondre √† max_features du TF-IDF
#                 loaded_vectorizer = trainer.load_model(bytes_data)  # Charge mod√®le ET vectorizer
#                 st.session_state.dl_model = trainer
#                 st.session_state.dl_vectorizer = loaded_vectorizer
#                 st.success("Mod√®le et vectorizer charg√©s avec succ√®s !")
#             except Exception as e:
#                 st.error(f"Erreur lors du chargement : {str(e)}")

#     # Section Pr√©diction (utilise TOUJOURS st.session_state.dl_model)
#     if 'dl_model' in st.session_state and 'dl_vectorizer' in st.session_state:
#         # ... (le reste du code de pr√©diction reste inchang√©)
#         st.subheader("üîÆ Pr√©dire des correspondances")

#         if "offer_text" not in st.session_state:
#             st.session_state.offer_text = "d√©veloppeur fullstack java"

#         input_offer = st.text_area(
#             "Texte de l'offre",
#             value=st.session_state.offer_text,
#             height=100
#         )
#         st.session_state.offer_text = input_offer

#         if st.button("üîç Pr√©dire les profils correspondants"):
#             offer_vec = st.session_state.dl_vectorizer.transform([input_offer.lower()]).toarray()
#             similarities = cosine_similarity(offer_vec, X_train).flatten()
#             top_indices = np.argsort(similarities)[-5:][::-1]

#             st.success("üèÜ Top 5 Profils Recommand√©s")
#             for i, idx in enumerate(top_indices):
#                 row = profils_df.iloc[idx]
#                 with st.container():
#                     cols = st.columns([1, 4])
#                     with cols[0]:
#                         st.metric(f"#{i+1}", f"{similarities[idx]:.1%}")
#                     with cols[1]:
#                         st.markdown(f"""
#                         **Poste:** {row['poste']}  
#                         **Localisation:** {row['localisation']}  
#                         **Exp√©rience:** {row['inter_exp']}
#                         """)
#                         with st.expander("Comp√©tences"):
#                             st.write(row['competences'])
#                     st.divider()
import streamlit as st
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import torch
import pickle

from matching_dl import MatchingDLTrainer

def run_deep_learning(profils_df):
    st.title("ü§ñ Matching Intelligent avec Deep Learning")

    if profils_df.empty:
        st.error("Aucun profil charg√©")
        st.stop()

    # Configuration du mod√®le dans la sidebar
    st.sidebar.header("Configuration du Mod√®le")
    model_type = st.sidebar.selectbox(
        "Type de mod√®le",
        options=["ann", "mlp", "dnn"],
        index=0,
        format_func=lambda x: {
            "ann": "ANN - R√©seau Standard",
            "mlp": "MLP - Multicouche",
            "dnn": "DNN - Profond (3+ couches)"
        }[x]
    )
    
    epochs = st.sidebar.slider("Nombre d'epochs", 5, 100, 20)
    lr = st.sidebar.selectbox("Taux d'apprentissage", 
                             [1e-2, 1e-3, 1e-4], 
                             index=1)

    profils_df['competence_clean'] = profils_df['competences'].str.lower().str.replace('[^\w\s]', '', regex=True)
    all_skills = profils_df['competence_clean'].tolist()

    vectorizer = TfidfVectorizer(max_features=500)
    X_train = vectorizer.fit_transform(all_skills).toarray()

    # Section Entra√Ænement
    if st.button("üîÑ Entra√Æner le mod√®le DL"):
        y_train = np.array([
            1 if any(k in skills.lower() for k in profils_df['key_word_ia']) else 0
            for skills in profils_df['competences']
        ])

        trainer = MatchingDLTrainer(input_dim=X_train.shape[1], model_type=model_type)
        metrics = trainer.train(X_train, y_train, epochs=epochs, lr=lr)
        st.session_state.dl_model = trainer
        st.session_state.dl_vectorizer = vectorizer
        st.success("‚úÖ Mod√®le entra√Æn√© avec succ√®s !")
        st.json(metrics)

        # Afficher des informations sur le mod√®le
        st.subheader("üìä Architecture du mod√®le")
        if model_type == "ann":
            st.write("**ANN (Artificial Neural Network)** - 1 couche cach√©e (256 neurones)")
        elif model_type == "mlp":
            st.write("**MLP (Multi-Layer Perceptron)** - 2 couches cach√©es (512 ‚Üí 256 neurones)")
        else:
            st.write("**DNN (Deep Neural Network)** - 4 couches cach√©es (1024 ‚Üí 512 ‚Üí 256 ‚Üí 128 neurones)")

    # Section Export/Import du mod√®le
    st.subheader("üì¶ Gestion du mod√®le")
    col1, col2 = st.columns(2)

    with col1:
        if 'dl_model' in st.session_state and 'dl_vectorizer' in st.session_state:
            model_bytes = st.session_state.dl_model.export_model(st.session_state.dl_vectorizer)
            st.download_button(
                label="üíæ Exporter le mod√®le",
                data=model_bytes,
                file_name="matching_model_and_vectorizer.pkl",
                mime="application/octet-stream"
            )
        else:
            st.warning("Entra√Ænez un mod√®le avant l'export")

    with col2:
        uploaded_file = st.file_uploader("üì§ Importer un mod√®le", type=["pkl"])
        if uploaded_file is not None:
            try:
                bytes_data = uploaded_file.read()
                trainer = MatchingDLTrainer(input_dim=500, model_type="ann")  # Type par d√©faut, sera √©cras√©
                loaded_vectorizer = trainer.load_model(bytes_data)
                st.session_state.dl_model = trainer
                st.session_state.dl_vectorizer = loaded_vectorizer
                st.success(f"Mod√®le {trainer.model_type} et vectorizer charg√©s avec succ√®s !")
            except Exception as e:
                st.error(f"Erreur lors du chargement : {str(e)}")

    # Section Pr√©diction
    if 'dl_model' in st.session_state and 'dl_vectorizer' in st.session_state:
        st.subheader("üîÆ Pr√©dire des correspondances")

        if "offer_text" not in st.session_state:
            st.session_state.offer_text = "d√©veloppeur fullstack java"

        input_offer = st.text_area(
            "Texte de l'offre",
            value=st.session_state.offer_text,
            height=100
        )
        st.session_state.offer_text = input_offer

        if st.button("üîç Pr√©dire les profils correspondants"):
            offer_vec = st.session_state.dl_vectorizer.transform([input_offer.lower()]).toarray()
            
            # Utilisation du mod√®le DL pour les probabilit√©s
            profile_probs = st.session_state.dl_model.predict_proba(X_train)
            
            # Combinaison des similarit√©s cosinus et des probabilit√©s du mod√®le
            similarities = cosine_similarity(offer_vec, X_train).flatten()
            combined_scores = 0.7 * profile_probs + 0.3 * similarities  # Pond√©ration
            
            top_indices = np.argsort(combined_scores)[-5:][::-1]

            st.success("üèÜ Top 5 Profils Recommand√©s")
            for i, idx in enumerate(top_indices):
                row = profils_df.iloc[idx]
                with st.container():
                    cols = st.columns([1, 4])
                    with cols[0]:
                        st.metric(f"#{i+1}", f"{combined_scores[idx]:.1%}")
                    with cols[1]:
                        st.markdown(f"""
                        **Poste:** {row['poste']}  
                        **Localisation:** {row['localisation']}  
                        **Exp√©rience:** {row['inter_exp']}
                        """)
                        with st.expander("Comp√©tences"):
                            st.write(row['competences'])
                    st.divider()